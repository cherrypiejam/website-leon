#+TITLE: Rust's Mutex, Atomics and UnsafeCell – Spooky Action at a Distance?
#+AUTHOR: Leon Schuermann
#+DATE: 2024-08-07 00:00:00-05:00
#+OPTIONS: toc:nil
#+EXCLUDE_TAGS: noexport

* Research / Notes                                                 :noexport:
- https://preshing.com/20130702/the-happens-before-relation/
  - https://whenderson.dev/blog/rust-mutexes/
- https://whenderson.dev/blog/implementing-atomics-in-rust/
- https://darkcoding.net/software/rust-atomics-on-x86/
- Rust atomics implementation:
  - https://github.com/rust-lang/rust/blob/8f63e9f8732d8688f2b5e1c816569f65ee185c7e/library/core/src/sync/atomic.rs#L2416
  - https://github.com/rust-lang/rust/blob/8f63e9f8732d8688f2b5e1c816569f65ee185c7e/library/core/src/sync/atomic.rs#L3306


* Frontmatter                                                      :noexport:

#+NAME: frontmatter
#+BEGIN_SRC nix :tangle frontmatter.nix
  { orgSource, pkgs, lib, util, ... }:
  util.orgMeta orgSource // {
    unpublished = false;
    tags = [ "rust" ];
    abstractTag = "abstract";
  }
#+END_SRC

#+NAME: org_setup
#+BEGIN_SRC elisp :results none
  (require 'ox-extra)
  (ox-extras-activate '(ignore-headlines))
#+END_SRC

* Intro                                                     :ignore:abstract:

A defining feature of Rust is its concept of /aliasing ⊕
mutability/. This rule governs that at any time a value may either
have multiple /immutable/ shared references, or a single /mutable/
unique reference, and never both. While this greatly helps in
producing fast, efficient and correct code, it can be limiting. To
this end, Rust also features types that bend these rules, like
src_rust[:exports code]{Mutex}, src_rust[:exports code]{RwLock},
src_rust[:exports code]{Cell}, src_rust[:exports code]{RefCell}, and
the ominous src_rust[:exports code]{UnsafeCell} types. In this post we
explore how these types interact with Rust's type system and concepts
of /references/ and /aliasing ⊕ mutability/. We do so by looking at
how the src_rust[:exports code]{AtomicUsize} and src_rust[:exports
code]{Mutex} types are implemented, how violating Rust's assumptions
can lead to incorrect optimizations by the compiler, and the
surprising /global/ impact of synchronization primitives.

#+TOC: headlines 1

* Atomics From Scratch

William Henderson's blog features a great article on how to [[https://whenderson.dev/blog/implementing-atomics-in-rust/][implement
Rust's atomic types]] (and [[https://whenderson.dev/blog/rust-mutexes/][ultimately even Mutexes]]) from scratch. I
encourage reading the full article, but will repeat the essential
parts of the code here (for an AMD64 CPU) as well:

#+begin_src rust -n
  pub struct AtomicUsize {
      inner: UnsafeCell<usize>,
  }

  unsafe impl Send for AtomicUsize {}
  unsafe impl Sync for AtomicUsize {}

  impl AtomicUsize {
      pub const fn new(v: usize) -> Self {
	  Self {
	      inner: UnsafeCell::new(v),
	  }
      }
      pub fn load(&self) -> usize {
	  unsafe { *self.inner.get() }
      }
      pub fn store(&self, v: usize) {
	  unsafe {
	      asm!(
		  "lock; xchg [{address}], {v}",
		  address = in(reg) self.inner.get(),
		  v = in(reg) v
	      );
	  }
      }
  }
#+end_src

We start by defining our src_rust[:exports code]{AtomicUsize} type to be a
wrapper around an src_rust[:exports code]{UnsafeCell<usize>}. This container
type allows us to modify its contents even if we hold just a shared reference to
it (a concept known as /interior mutability/). As put in William Henderson's
post:
#+begin_quote
The src_rust[:exports code]{usize} needs to be within an
src_rust[:exports code]{UnsafeCell} to effectively opt out of Rust’s
borrow checker [...]
#+end_quote

Whereas src_rust[:exports code]{UnsafeCell} is the underlying primitive type
that causes the Rust compiler to provide these semantics for the objects
contained therein, it is more commonly used in safe wrappers such as
src_rust[:exports code]{Cell} or src_rust[:exports code]{RefCell}.

It is important to note that despite allowing interior mutability,
src_rust[:exports code]{UnsafeCell} does not perform any synchronization on its
own—one of the key distinguishing features of other types like src_rust[:exports
code]{Mutex}. This restriction is visible by the fact that src_rust[:exports
code]{UnsafeCell} does not implement the src_rust[:exports code]{Sync}
trait. Without this trait, Rust will not allow us to share a reference to this
type between threads, and thus guarantees that src_rust[:exports
code]{UnsafeCell} will never have unsynchronized accesses.

However, this property is problematic for our src_rust[:exports
code]{AtomicUsize} type whose entire purpose is to enable reading and
writing of a shared value among multiple threads! For this, the documentation of
src_rust[:exports code]{UnsafeCell} provides us with an escape hatch:
#+begin_quote
At all times, you must avoid data races. If multiple threads have access to the
same UnsafeCell, then any writes must have a proper happens-before relation to
all other accesses (or use atomics).
#+end_quote

OK, so to safely use an src_rust[:exports code]{UnsafeCell} between threads we
will need to perform synchronization ourselves (establish a /happens-before
relation/) or use atomics. As the above is building an atomic usize primitive,
we should thus be safe to tell the Rust compiler that our own src_rust[:exports
code]{AtomicUsize} type is indeed both src_rust[:exports code]{Send} (can be
moved between threads) and src_rust[:exports code]{Sync} (can be concurrently
used from multiple threads). Because the Rust compiler cannot check whether this
is actually the case, implementing these traits are src_rust[:exports
code]{unsafe} operations.

The above example makes use of the fact that, in AMD64, a read-lock is not
required when all operations that modify a shared value use locking
instructions. As such, we can simply dereference the value stored in the
src_rust[:exports code]{UnsafeCell}:
#+begin_quote
Since our implementations of all the methods which change the value will be
atomic, the CPU won’t let us observe the value in the middle of an
operation. Therefore, to load the value, we can simply return the current value
of the UnsafeCell.
#+end_quote
For writing, William Henderson's version uses an AMD64 inline assembly
instruction that performs a locking store operation.

* Optimized to the Breaking Point

With our src_rust[:exports code]{AtomicUsize} implemented, let's write a basic
reader / writer test case: we spawn a thread that spin-waits
until the shared atomic assumes a non-zero value, and another that writes a =1= to
it after a short delay ([[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=062364916552c3debff119c59e982dc0][Rust playground]]).

#+begin_src rust -n
  fn reader(a: &AtomicUsize) {
      while a.load() == 0 {
	  // Wait until `a` contains a non-zero value.
      }
  }

  fn writer(a: &AtomicUsize) {
      a.store(1);
  }

  fn main() {
      let shared_atomic = Arc::new(AtomicUsize::new(0));

      // Start up the reader thread:
      let shared_atomic_clone = shared_atomic.clone();
      let join_handle = std::thread::spawn(
	  move || reader(&shared_atomic_clone));

      // Wait for 50ms:
      std::thread::sleep(Duration::from_millis(50));

      // Write a non-zero value to the shared atomic:
      writer(&shared_atomic);

      // Wait for the reader thread to exit:
      join_handle.join().unwrap()
  }
#+end_src

When we run this example with the above src_rust[:exports code]{AtomicUsize}
implementation in a /debug/ build, it runs for about 50ms—as expected. However,
once we turn on more aggressive compiler optimizations by building in /release/
mode, the program does not quit and fully consumes one CPU core ... hm, what's
going on here?

If we look at the assembly of our src_rust[:exports code]{fn reader} (by
selecting "Show Assembly" in [[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=08e7afa7c1a259cc3170c953c5736720][this Rust playground]]) we see that Rust generates
the following machine code:

#+begin_src asm -n
  fn_reader:
          cmpq  $0, (%rdi)
          je    .LBB24_1
          retq

  .LBB24_1:
          jmp   .LBB24_1
#+end_src

Even though our source code calls src_rust[:exports code]{a.load()} for each
loop iteration, it seems like the generated function only reads the
src_rust[:exports code]{usize} value (at an adress in =%rdi=) once and, if it
happens to be equal to =0=, jumps into an infinite loop at symbol
src_asm[:exports code]{.LBB24_1}. That's not at all what we want!

It seems that the Rust compiler determines that it should be enough to read the
value returned by src_rust[:exports code]{a.load()} once, and then assumes that
it may never change. If it was =0= when entering this function, because the
function never modifies it, the compiler thus assumes that it will always stay
at this value and never return from the src_rust[:exports code]{while}
loop. This seems quite counter-intuitive given that the entire purpose behind
src_rust[:exports code]{UnsafeCell} is to /allow/ interior mutability. Thus, Rust
should need to expect that its underlying value changes even though we only hold
an immutable (src_rust[:exports code]{&}) reference to it.

We can observe similar behavior with the following minimal example
([[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=c19065067ab8ce6631858069beb0a963][Playground]]). Here we use Rust's src_rust[:exports code]{Cell} type instead of
src_rust[:exports code]{UnsafeCell} for convenience; src_rust[:exports
code]{Cell} is nothing more than a safe wrapper around src_rust[:exports
code]{UnsafeCell}.
#+begin_src rust -n
pub fn cell_test(a: &Cell<usize>) -> bool {
    let first = a.get();
    let second = a.get();
    first == second
}
#+end_src

Looking at the generated assembly, Rust turns this function into a simple
"return true":
#+begin_src asm -n
  fn_cell_test:
	  movb 	1, %al
	  retq
#+end_src

* src_rust[:exports code]{UnsafeCell} Revisited

With the above behavior, one might wonder what an src_rust[:exports
code]{UnsafeCell} is actually useful for? We cannot—by default—share it between
threads and clearly its concepts of /interior mutability/ do not extend to give
any guarantees in the face of /concurrent/ accesses to its memory. So what's the
point? To illustrate this, we can extend the above example like so:
#+begin_src rust -n
  use std::cell::Cell;

  pub fn cell_test(a: &Cell<usize>, writer: &dyn Fn()) -> bool {
      let first = a.get();
      writer();
      let second = a.get();
      first == second
  }

  pub fn main() {
      let a = Cell::new(0);
      println!(
	  "Cell contents identical? {:?}",
	  cell_test(&a, &|| { a.set(1) })
      );
  }
#+end_src

We extend our src_rust[:exports code]{fn cell_test} to take an
additional src_rust[:exports code]{writer} function reference
argument. This src_rust[:exports code]{writer} function is then called
in between our first and second read of the src_rust[:exports
code]{Cell<usize>}.

After this change, we can observe that Rust instead generates the following
assembly[fn:1] ([[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=71cd229c9306fc2e8ec56ff0cbac9cbc][Playground]]):
#+begin_src asm -n
  fn_cell_test:
          pushq %r14
          pushq %rbx
          pushq %rax
          movq  %rdi, %rbx
          movq  (%rdi), %r14
          movq  %rsi, %rdi
          callq *40(%rdx)
          cmpq  (%rbx), %r14
          sete  %al
          addq  $8, %rsp
          popq  %rbx
          popq  %r14
          retq
#+end_src



There's a lot more happening here. The important bits are:
- on line 5, we copy the pointer to our src_rust[:exports code]{Cell<usize>},
  initially passed in register src_asm[:exports code]{%rdi}, into src_asm[:exports
  code]{%rbx},
- on line 6, we read the contents of the src_rust[:exports code]{Cell<usize>}
  into register src_asm[:exports code]{%r14},
- on line 8, we invoke the src_rust[:exports code]{writer} function,
- and finally, on lines 9 and 10 we compare the current contents of
  the src_rust[:exports code]{Cell<usize>} to the value we read on
  line 6, and set the return value (src_asm[:exports code]{%al}) to
  src_rust[:exports code]{true} (src_asm[:exports code]{$1}) or
  src_rust[:exports code]{false} (src_asm[:exports code]{$0}) using
  the src_asm[:exports code]{sete} instruction.

This makes sense: we're handing out two shared references to the
src_rust[:exports code]{Cell<usize>}, one passed to src_rust[:exports code]{fn
cell_test} directly, and one embedded in the closure constructed on line 14 of
src_rust[:exports code]{fn main}. When we invoke src_rust[:exports code]{writer}
on line 5, because it also holds to a reference to this src_rust[:exports
code]{Cell}, we must assume that its contents have been changed and thus re-read
it.

We can force the compiler to generate quite similar assembly when we replace the
invocation of src_rust[:exports code]{writer} with a call to src_rust[:exports
code]{std::hint::black_box}:
#+begin_src rust -n
  pub fn cell_test(a: &Cell<usize>) -> bool {
      let first = a.get();
      std::hint::black_box(a);
      let second = a.get();
      first == second
  }
#+end_src

From [[https://doc.rust-lang.org/stable/std/hint/fn.black_box.html][its documentation]], src_rust[:exports code]{std::hint::black_box} is
#+begin_quote
[an] identity function that hints to the compiler to be maximally pessimistic
about what src_rust[:exports code]{black_box} could do.
#+end_quote

In this case, one of the possible effects that the compiler assumes
src_rust[:exports code]{black_box} to have is performing an src_rust[:exports
code]{a.set(1)} operation. Hence it makes sense that src_rust[:exports
code]{black_box} would force the compiler to re-read the src_rust[:exports
code]{Cell}'s contents on the second call to src_rust[:exports code]{a.get()}.

However, things get even more interesting when we replace this with a call to
src_rust[:exports code]{std::hint::black_box(())}. In this case, the Rust
compiler will be /maximally pessimistic/ about what src_rust[:exports
code]{black_box} could do to its function argument, an instance of the unit
type. Its documentation doesn't say anything about what could happen to other
variables such as src_rust[:exports code]{a}. Yet, when we compile the following
code...
#+begin_src rust -n
  pub fn cell_test(a: &Cell<usize>) -> bool {
      let first = a.get();
      std::hint::black_box(());
      let second = a.get();
      first == second
  }
#+end_src
...we see that the src_rust[:exports code]{Cell} is indeed read /twice/. Curious!
#+begin_src asm -n
  fn_cell_test:
	  movq	(%rdi), %rax
	  cmpq	(%rdi), %rax
	  sete	%al
	  retq
#+end_src

From these findings we can derive two properties of src_rust[:exports
code]{UnsafeCell}:

1. For part of the code where the Rust compiler assumes that it has /full
   visibility/ over all operations carried out on all references that are
   accessible, it may make assumptions about an src_rust[:exports
   code]{UnsafeCell}'s contents not changing.

2. Across any code path where Rust does not have this degree of visibility
   (e.g., by calling into an opaque function, foreign function, or invoking a
   src_rust[:exports code]{black_box}), it instead assumes that an
   src_rust[:exports code]{UnsafeCell}'s contents may have changed.

It is important to note that Rust generally assumes that an src_rust[:exports
code]{UnsafeCell} is not shared across multiple threads (apart from the
/happens-before/ condition mentioned above). Thus, even though multiple
references may exist for any src_rust[:exports code]{UnsafeCell} at any time, as
long as the compiler determines that the /current thread/ does not modify a
particular reference, and no other code is invoked that could modify any other
reference to this src_rust[:exports code]{UnsafeCell}, its contents will not
change.

This explains the behavior of our src_rust[:exports code]{AtomicUsize}
example. As part of the load function, we're simply accessing and dereferencing
the contents of the inner src_rust[:exports code]{UnsafeCell}. Rust does not
assume that this value is shared with any other concurrent thread, and by having
full visibility of the operations carried out within the src_rust[:exports
code]{reader} thread, it determines that its value may never be modified within
this function; hence reading its value once ought to be sufficient.

* Concurrency and src_rust[:exports code]{UnsafeCell}

This raises the question: given that src_rust[:exports code]{UnsafeCell} does
not deliver our desired semantics, how are src_rust[:exports code]{AtomicUsize},
src_rust[:exports code]{Mutex}, and friends actually implemented in Rust? Well
... using src_rust[:exports code]{UnsafeCell}!

Looking at the src_rust[:exports code]{core::atomic} module with macros
expanded, the implementation of src_rust[:exports code]{AtomicUsize} looks
roughly like this:
#+begin_src rust -n
  pub struct AtomicUsize {
      v: UnsafeCell<usize>,
  }
#+end_src

This seems virtually identical to how our own src_rust[:exports
code]{AtomicUsize} is implemented. However, there is a crucial difference when
we look at the src_rust[:exports code]{AtomicUsize::load} function:
#+begin_src rust -n
  impl AtomicUsize{
      pub fn load(&self, order: Ordering) -> usize {
	  unsafe { atomic_load(self.v.get(), order) }
      }
      ...
  }

  #[inline]
  unsafe fn atomic_load<T: Copy>(dst: *const T, order: Ordering) -> T {
      match order {
	  Relaxed => intrinsics::atomic_load_relaxed(dst),
	  Acquire => intrinsics::atomic_load_acquire(dst),
	  ...
      }
  }
#+end_src

In addition to the ability to specify a desired /ordering/ or /consistency
model/, this implementation uses /compiler intrinsics/ to generate the
corresponding atomic operations. This means that the compiler will automatically
generate the appropriate instructions for the target architecture to perform
these atomic operations. These intrinsics can also enforce other high-level
constraints, such as on the order of operations. In this case, the
src_rust[:exports code]{Relaxed} ordering model corresponds to our custom
implementation of the src_rust[:exports code]{AtomicUsize} type.

Here is a [[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=5a9b74d7d58d8e46fcd57f64a44a4c73][Rust playground]] that uses the standard library's src_rust[:exports
code]{AtomicUsize} type with src_rust[:exports code]{Ordering::Relaxed}
instead. Looking at the generated assembly, we can observe that Rust turns both
the src_rust[:exports code]{load} and src_rust[:exports code]{store} operations
into simple reads and writes with the src_asm[:exports code]{movq} instruction:
#+begin_src asm -n
  fn_reader:
	  movq	(%rdi), %rax
	  testq	%rax, %rax
	  je	fn_reader
	  retq

  fn_writer:
	  movq	$1, (%rdi)
	  retq
#+end_src

Superficially, it seems that our implementation and the Rust standard library's
should thus be functionally equivalent! We're generating essentially the same
machine code, and rely on the target-architecture specific guarantee that
naturally aligned load and store operations of src_rust[:exports code]{usize}
values are always atomic.

However, there is another crucial difference: the generated assembly re-reads
the src_rust[:exports code]{UnsafeCell}'s value in each loop iteration. Thus,
this src_rust[:exports code]{AtomicUsize} implementation generates /actually
correct/ code—despite producing effectively equivalent instructions otherwise!
Now seems like a good time to revisit the src_rust[:exports code]{UnsafeCell}'s
documentation concerning concurrency:
#+begin_quote
At all times, you must avoid data races. If multiple threads have access to the
same UnsafeCell, then any writes must have a proper happens-before relation to
all other accesses (or use atomics).
#+end_quote

The phrasing here is unfortunate in two regards:
- When we don't have a proper /happens-before relation/ (we'll get to that
  later), we need to use atomic operations for concurrent accesses on the
  src_rust[:exports code]{UnsafeCell}'s memory instead. However, clearly these
  atomic operations must /not only/ be used for /writes/, but also for /reads/!
- It is not only important that the generated machine code instructions are
  atomic (as is the case with our custom src_rust[:exports
  code]{AtomicUsize}). We /also/ need to communicate to the Rust compiler that
  these instructions are /used as atomic operations/. Somehow, something magic
  about the src_rust[:exports code]{atomic_load_} intrinsics causes the compiler
  to not assume that the memory behind this reference cannot change.

We can confirm the latter by looking at the LLVM intermediate representation
(IR) that the Rust compiler generates. This format is then used by the LLVM
compiler backend to generate optimized machine code for various
architectures. However, for those optimizations to be correct, the Rust compiler
has to encode a bunch of information on program behavior into this LLVM IR.

Rust generates the following slightly cryptic LLVM IR for src_rust[:exports
code]{fn reader} using our custom src_rust[:exports code]{AtomicUsize}:
#+begin_src llvm -n
; Function Attrs: nofree noinline norecurse nosync nounwind nonlazybind memory(argmem: read) uwtable
define dso_local void @fn_reader(ptr nocapture noundef nonnull readonly align 8 %a) unnamed_addr #4 {
start:
  %_2.pr = load i64, ptr %a, align 8
  %0 = icmp eq i64 %_2.pr, 0
  br i1 %0, label %bb1, label %bb3

bb1:                                              ; preds = %start, %bb1
  br label %bb1

bb3:                                              ; preds = %start
  ret void
}
#+end_src

Let's see what changes if we swap this out for the standard library's
src_rust[:exports code]{AtomicUsize}:
#+begin_src llvm -n
; Function Attrs: nofree noinline norecurse nounwind nonlazybind memory(argmem: readwrite) uwtable
define dso_local void @fn_reader(ptr nocapture noundef nonnull readonly align 8 %a) unnamed_addr #4 {
start:
  br label %bb1

bb1:                                              ; preds = %bb1, %start
  %0 = load atomic i64, ptr %a monotonic, align 8
  %1 = icmp eq i64 %0, 0
  br i1 %1, label %bb1, label %bb3

bb3:                                              ; preds = %bb1
  ret void
}
#+end_src

The changes on line 4 and 7 respectively make sense: instead of a
src_llvm[:exports code]{load} instruction, Rust generates a src_llvm[:exports
code]{load atomic} LLVM instruction. The added src_llvm[:exports
code]{monotonic} here is the desired consistency model, where src_llvm[:exports
code]{monotonic} corresponds to Rust's src_rust[:exports
code]{Ordering::Relaxed}.

The branching behavior also changes: whereas in the former version the label
src_llvm[:exports code]{bb1:} forms a simple infinite loop, the latter performs
a read every time it jumps back to src_llvm[:exports code]{bb1:}.

However, the addition of the src_llvm[:exports code]{nosync} function attribute
for our custom src_rust[:exports code]{AtomicUsize} version is perhaps most
telling. Here's what [[https://llvm.org/docs/LangRef.html][LLVM's language reference]] says about this attribute:
#+begin_quote
This function attribute indicates that the function does not communicate
(synchronize) with another thread through memory or other well-defined
means. Synchronization is considered possible in the presence of atomic accesses
that enforce an order, thus not “unordered” and “monotonic”, volatile accesses,
as well as convergent function calls. [...]

If a nosync function does ever synchronize with another thread, the behavior is
undefined.
#+end_quote

This means that Rust compiler intrinsics such as src_rust[:exports
code]{intrinsics::atomic_load_relaxed} implicitly tell the compiler that code
may use these atomic operations to synchronize with other concurrent
code. Without these operations, Rust simply assumes that variables are not
concurrently modified by other code and is thus allowed to reason about them as
if they aren't shared with other threads at all. Ultimately, this is safe as
src_rust[:exports code]{UnsafeCell} is not src_rust[:exports code]{Sync}—by
default, it cannot be shared between threads. And our custom src_rust[:exports
code]{AtomicUsize} is /unsound/, as we promise to the compiler that
src_rust[:exports code]{AtomicUsize} is safe to share between threads, but do
not adequately instruct the compiler to synchronize all accesses to underlying
memory. This is regardless of whether or not the generated machine code uses
atomic instructions.

* Spooky Action at a Distance?

Finally, let's look at how src_rust[:exports code]{Mutex} is implemented on top
of src_rust[:exports code]{UnsafeCell}. The src_rust[:exports code]{Mutex} type
in the standard library is implemented based on an src_rust[:exports
code]{UnsafeCell} and a platform-specific mutex locking mechanism (we can ignore
src_rust[:exports code]{poison} for now):
#+begin_src rust -n
  pub struct Mutex<T: ?Sized> {
      inner: sys::Mutex,
      poison: poison::Flag,
      data: UnsafeCell<T>,
  }
#+end_src

Here, src_rust[:exports code]{sys::Mutex} is platform specific, and happens to
use the futex implementation on Linux:
#+begin_src rust -n
  // std::sys::sync::mutex::futex::Mutex
  pub struct Mutex {
      futex: AtomicU32,
  }
#+end_src

The atomic integer type within this src_rust[:exports code]{futex::Mutex} also
varies between systems and happens to be src_rust[:exports code]{AtomicU32} for
UNIX. Recall from the src_rust[:exports code]{AtomicUsize} example above that
these atomic types in turn are just another wrapper around an src_rust[:exports
code]{UnsafeCell}. /It's src_rust[:exports code]{UnsafeCell} all the way down!/

To get access to the contents of a mutex we need to lock it. The
src_rust[:exports code]{Mutex::lock} function is implemented as follows:
#+begin_src rust -n
  pub fn lock(&self) -> LockResult<MutexGuard<'_, T>> {
      unsafe {
	  self.inner.lock();
	  MutexGuard::new(self)
      }
  }
#+end_src
After calling src_rust[:exports code]{lock()} on the platform-specific inner
src_rust[:exports code]{Mutex} struct, the user is provided a src_rust[:exports
code]{MutexGuard} object. This src_rust[:exports code]{MutexGuard} is simply a
wrapper that retains a reference to the original src_rust[:exports
code]{Mutex}. Notably, it provides /entirely unsynchronized access/ to the
underlying data (which is simply contained in a src_rust[:exports
code]{UnsafeCell}):
#+begin_src rust -n
  impl<T: ?Sized> Deref for MutexGuard<'_, T> {
      type Target = T;

      fn deref(&self) -> &T {
	  unsafe { &*self.lock.data.get() }
      }
  }
#+end_src

This function looks a lot like our custom src_rust[:exports
code]{AtomicUsize::load} implementation. In fact, what happens here is quite
similar to this first example: a reference to an src_rust[:exports
code]{UnsafeCell} is shared between threads, and accesses to the
src_rust[:exports code]{UnsafeCell}'s contents do not use any special intrinsics
or atomic operations. So ... this surely isn't sound in practice?!

Of course, Rust's src_rust[:exports code]{Mutex} implementation is correct. To
understand why, we need to look into the implementation of the src_rust[:exports
code]{inner.lock()} method. Here's the implementation of src_rust[:exports
code]{futex::Mutex::lock}:
#+begin_src rust -n
  pub fn lock(&self) {
      if self.futex.compare_exchange(UNLOCKED, LOCKED, Acquire, Relaxed).is_err() {
	  self.lock_contended();
      }
  }
#+end_src

Essentially, the =futex= implementation uses an atomic integer shared between
threads to record the current lock state of the mutex. When attempting to lock
the mutex, it uses a /compare-exchange/ operation to atomically write a value of
=1= (/locked/) into this integer, if any only if the current value of the atomic
integer currently contains a value of =0= (/unlocked/). If the mutex is
currently locked, it asks the operating system to inform it when the lock is
free again (src_rust[:exports code]{self.lock_contended()}). See [[https://eli.thegreenplace.net/2018/basics-of-futexes/][this excellent
post]] by Eli Bendersky for more context on =futex=.

Unfortunately, the implementation of src_rust[:exports
code]{AtomicU32::compare_exchange} (as invoked on src_rust[:exports
code]{self.futex}) is too complex to fully depict here. However, ultimately this
function ends up calling into the following helper function:
#+begin_src rust -n
  unsafe fn atomic_compare_exchange<T: Copy>(
      dst: *mut T,
      old: T,
      new: T,
      success: Ordering,
      failure: Ordering,
  ) -> Result<T, T> {
      let (val, ok) = unsafe {
	  match (success, failure) {
	      (Relaxed, Relaxed) => {
		  intrinsics::atomic_cxchg_relaxed_relaxed(dst, old, new)
	      }
	      (Relaxed, Acquire) => {
		  intrinsics::atomic_cxchg_relaxed_acquire(dst, old, new)
	      }
	      ...
#+end_src

The implementation here again uses compiler intrinsics to generate the
actual underlying machine code. By compiling a simplified version of
the above ([[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=ec5d5af6ea6a25ebef67e40914af67a6][Playground]]), we can confirm that these intrinsics generate
corresponding src_asm[:exports code]{lock cmpxchgb} instructions
/before/ the value stored in the src_rust[:exports code]{UnsafeCell}
is accessed:
#+begin_src asm -n
  fn_reader:
	  movb	$1, %cl
  .LBB24_1:
	  xorl	%eax, %eax
	  lock cmpxchgb %cl, 8(%rdi)
	  jne	.LBB24_1
	  cmpq	$0, (%rdi)
	  movb	$0, 8(%rdi)
	  je	.LBB24_1
	  retq
#+end_src

Thus, if used correctly, a src_rust[:exports code]{compare_exchange}
operation seems to be sufficient to synchronize accesses to a Rust
src_rust[:exports code]{UnsafeCell} across threads.

...But wait! Our Mutex holds not one, but *two* src_rust[:exports
code]{UnsafeCell}s internally. And we only used a src_rust[:exports
code]{compare_exchange} on /one/ of the src_rust[:exports
code]{UnsafeCell}s, namely the one holding information on whether the
src_rust[:exports code]{Mutex} is locked or not. The other
src_rust[:exports code]{UnsafeCell} holding the actual data that the
mutex is supposed to be synchronized never has any atomic or locking
instructions used on it. In fact, we're _still_ using the exact some
problematic code snippet (src_rust[:exports code]{*self.inner.get()})
that led to problems with our src_rust[:exports code]{AtomicUsize} in
the first place!

What we're observing here is that *a local operation performed on
/one/ value has implicit impact on how the compiler treats assumptions
around /another/, completely independent value*. I think that this can
be quite surprising and unintuitive; you might call it "spooky action
at a distance".

Indeed, the src_rust[:exports code]{atomic_cxchg} compiler intrinsic
again does more than meets the eye: in addition to generating the
appropriate atomic machine instruction(s), it can also establish an
/ordering/, or /happens-before relation/ of other program
operations. For example, when performing an atomic load operation with
an src_rust[:exports code]{Acquire} ordering, the program is granted
the following guarantee, [[https://doc.rust-lang.org/stable/std/sync/atomic/enum.Ordering.html#variant.Acquire][per Rust's documentation]]:
#+begin_quote
When coupled with a load, if the loaded value was written by a store
operation with src_rust[:exports code]{Release} (or stronger)
ordering, then all subsequent operations become ordered after that
store. In particular, all subsequent loads will see data written
before the store.
#+end_quote
It is important to understand that these ordering requirements can not
only influence the types of atomic machine instructions ultimately
executed by the hardware. They can also influence other compiler
assumptions and program optimizations, and in particular, limit the
flexibility that a compiler has to re-order or elide operations that
access memory.

Revisiting the example of our src_rust[:exports code]{Mutex}
implementation ([[https://play.rust-lang.org/?version=stable&mode=release&edition=2021&gist=ec5d5af6ea6a25ebef67e40914af67a6][Playground]]), there are two basic guarantees we need to
maintain:
1. We must never give out concurrent access to the src_rust[:exports
   code]{data} field. We do this by acquiring a unique lock with a
   shared atomic value.
2. By the next time a thread acquires a lock on the src_rust[:exports
   code]{Mutex}, all changes made by the previous holder of the lock
   must be visible in this new thread.

And memory ordering specifications help us achieve this second
goal. In practice, when we load an atomic value with src_rust[:exports
code]{Ordering::Acquire}, we *prohibit* the compiler to /move reads/
on variables that /could be/ shared with other threads to /before/
this operation. As hinted at by the Rust documentation, this is not
enough on its own though: the compiler would still be able to move
writes beyond the point where the mutex is unlocked by the previous
holder of the lock. These writes would thus not necessarily be visible
to the new lock holder, infringing on our guarantees. For this reason,
we release the lock by performing another atomic operation, this time
with src_rust[:exports code]{Release} ordering—preventing this exact
optimization. So long as these atomic operations are performed in
tandem on the same atomic value, the compiler will provide us these
guarantees for *all*, global variables that may potentially be shared
with other threads.

* Conclusion

Concurrency and synchronization are tricky subjects on their own. As
we have seen above, things get even more nuanced when we throw Rust's
concepts around borrowing, references, and its compiler optimizations
into the mix. While many of these basic concepts were familiar to me
from both practical experience and theoretical computer science
lectures, seeing how they play in to the actual implementation of
concurrency primitives in a high-level language such as Rust is still
interesting (and at times surprising). I hope that this post can
demystify some of the /"magic"/ behavior and optimizations you may
observe around these constructs.

One of those particularly nebulous constructs to me has always been
src_rust[:exports code]{UnsafeCell}: /sure, it "opts out" of the Rust
borrow checker, but what other effects does it have?/ /We need to
"avoid data races", but how to do so exactly?/ Reasoning about this is
hard, in part because we need to consider both Rust's high-level
language invariants, low-level compiler optimization effects, _and_
their interactions. Some slightly clearer language in
src_rust[:exports code]{UnsafeCell}'s documentation could help a great
amount here. For instance, a "happens-before" relation is well-defined
by LLVM, but there is no clear documentation on which Rust compiler
intrinsics establish it.

While they make sense when thinking about, something particularly
surprising are the non-local /"spooky"/ effects that certain compiler
intrinsics have on other program behavior. Rust usually requires
developers to think _locally_ (/"is this reference still alive here?"/
or /"have this variable's contents been moved?"/). Instead, these
intrinsics have /implicit/, /global/ effects on program behavior after
compiler optimizations, and these effects do not manifest in Rust's
type system at all.

* Aside: What About src_rust[:exports code]{VolatileCell}?

Next to these concurrency primitives that Rust ships, some users
decide to develop their own. There is [[https://crates.io/crates/parking_lot][=parking_lot=]], a crate with more
efficient implementations of synchronization primitives. If you want
to avoid using locks at all, the [[https://crates.io/crates/lockfree][=lockfree=]] crate might be interesting
to you. And one of those special types that is popular among embedded
developers is src_rust[:exports code]{VolatileCell} (like in [[https://docs.rs/vcell/latest/vcell/][=vcell=]],
or [[https://docs.tockos.org/kernel/utilities/cells/struct.volatilecell][its Tock equivalent]]). In this section, we will try to apply some of
the concepts learned above to this construct. Note that while much of
the content of this section is trying to reason about the safety of
src_rust[:exports code]{VolatileCell}, **I do not claim for any of
this to be authoritative information**. These are mostly just notes I
wrote down while reasoning about this myself.

Embedded systems or bare-metal code commonly operate over memory that
is not backed by RAM in the conventional sense. Instead, these memory
address represent registers that are provided by peripherals,
so-called "Memory Mapped I/O" (MMIO).

In general, these peripherals run in parallel to the CPU—thus, it may
be reasonable to effectively model them to be separate threads in your
system. They "share" certain MMIO memory addresses with your program
and may, at times, even be able to write to arbitrary regular program
memory too. Similar to threads, they should follow a contract for
/when/ it is safe to read from or write to certain memory.

However, despite behaving similar to a separate thread, these devices
can differ in one significant regard: memory accesses (that is, both
read or write operations) may also have arbitrary, device-specific
side effects. A common example is that of a serial console (UART)
controller. These devices feature internal queues that hold on to a
limited amount of received bytes, which are later read by the
CPU. While a separate thread might expose this as, e.g., a ring-buffer
protected by a Mutex, such MMIO peripherals can implement a more
efficient, lock-free way of exposing this information. Following
example of a read-queue implemented within a serial console
controller, it may expose the current queue's head element for every
read to a specific queue register, but on each read /also/ immediately
discard (/dequeue/) this head element.

When paired with compiler optimizations as we've seen above, this can
be problematic. The compiler makes many assumptions on how memory will
behave, which can lead it to elide certain accesses, reorder them, or
even insert spurious accesses when it believes this to be safe. These
peripherals, though, don't share the compilers understanding around
memory behavior. Thus, an optimizing compiler can translate a driver
that correctly implements a device's hardware contract into something
incorrect, or even dangerous (e.g., when a peripheral can override
program memory).

To avoid these issues, Rust provides /volatile/ memory operations
(i.e., [[https://doc.rust-lang.org/stable/std/ptr/fn.read_volatile.html][reads]] and [[https://doc.rust-lang.org/stable/std/ptr/fn.write_volatile.html][writes]]). Volatile operations provide some unique
guarantees:
#+begin_quote
Volatile operations are intended to act on I/O memory, and are
guaranteed to not be elided or reordered by the compiler across other
volatile operations.
#+end_quote
#+begin_quote
The compiler shouldn’t change the relative order or number of volatile
memory operations.
#+end_quote

However, notably, volatile operations are independent from atomic
operations:
#+begin_quote
Just like in C, whether an operation is volatile has no bearing
whatsoever on questions involving concurrent access from multiple
threads. Volatile accesses behave exactly like non-atomic accesses in
that regard. In particular, a race between a src_rust[:exports
code]{read_volatile} and any other operation (reading or writing) on
the same location is undefined behavior.
#+end_quote

These properties make their interactions with synchronization,
ordering, and other compiler optimizations all the more
interesting. For this post, we'll focus only on three things that have
recently come up in discussions around Tock's use of src_rust[:exports
code]{VolatileCell}. src_rust[:exports code]{VolatileCell} is not
something that Rust provides; you can view its implementation [[https://docs.tockos.org/src/tock_cells/volatile_cell.rs][here]]. In
fact, its soundness is subject to debate (e.g., [[https://github.com/rust-lang/unsafe-code-guidelines/issues/411#issuecomment-1581214968][in the Rust unsafe
code guidelines]]) and is the motivation for this post.

** Introducing src_rust[:exports code]{VolatileCell}

src_rust[:exports code]{VolatileCell}'s purpose is to make a
developer's life easier: peripherals that expose an MMIO-based
interface typically do so by having their registers laid out such
that it can be modeled like a =#[repr(C)]= struct, like [[https://github.com/tock/tock/blob/dee00dc23d32dd8116cb88b705ffaba11e950e72/chips/sifive/src/uart.rs#L21-L37][this]]:
#+begin_src rust -n
#[repr(C)]
pub struct UartRegisters {
    /// Transmit Data Register
    txdata: u32,
    /// Receive Data Register
    rxdata: u32,
    /// Transmit Control Register
    txctrl: u32,
    /// Receive Control Register
    rxctrl: u32,
    /// Interrupt Enable Register
    ie: u32,
    /// Interrupt Pending Register
    ip: u32,
    /// Baud Rate Divisor Register
    div: u32,
}
#+end_src

If we then cast a pointer at the address at which the peripheral's
MMIO interface is exposed in memory (its /base address/) to a
src_rust[:exports code]{&mut UartRegisters} reference, we have a
convenient way to access its registers.

Unfortunately, doing so would not be sound. Given that the peripheral
can act like a different thread and change the values of these
registers independent of the CPU, creating a unique, mutable reference
to this struct would infringe on Rust's "no mutable aliasing"
requirement. Despite that, regular memory accesses are subject to the
compiler optimizations described above; for these registers, we need
all accesses to be /volatile/.

This is the niche that src_rust[:exports code]{VolatileCell} fills!
It's quite simple, and like all things we discuss today wraps an
src_rust[:exports code]{UnsafeCell} internally:
#+begin_src rust -n
  pub struct VolatileCell<T> {
      value: UnsafeCell<T>,
  }
#+end_src

To implement these volatile accesses, it features custom
src_rust[:exports code]{get} and src_rust[:exports code]{set} methods
respectively:
#+begin_src rust -n
  impl<T> VolatileCell<T> {
      pub fn get(&self) -> T {
	  // self.value.get() returns a *mut T pointer here:
	  unsafe { ptr::read_volatile(self.value.get()) }
      }

      pub fn set(&self, value: T) {
	  unsafe { ptr::write_volatile(self.value.get(), value) }
      }
  }
#+end_src

Thus, in essence, src_rust[:exports code]{VolatileCell} combines the
properties of interior mutability with those of volatile memory
accesses. With it, we can transform the above struct into a similar
version, while still benefiting from a convenient API:
#+begin_src rust -n
pub struct UartRegisters {
    /// Transmit Data Register
    txdata: VolatileCell<u32>,
    /// Receive Data Register
    rxdata: VolatileCell<u32>,
    ...
#+end_src
Neat.

** src_rust[:exports code]{VolatileCell} and =dereferenceable=

Unfortunately, src_rust[:exports code]{VolatileCell} has issues. I
encourage you to read [[https://github.com/rust-lang/unsafe-code-guidelines/issues/411][the discussion on the Rust unsafe code]]
guidelines, but in short, this problem comes from the fact that all
references in Rust are marked as =dereferenceable= by default.

This dereferenceability means that the compiler is free to, for
instance as part of certain optimizations, insert a /spurious read/ to
the reference's contents. And performing such a spurious read on a
memory location where reads can have side effects can mean that for
many uses, using this abstraction can be dangerous and unsound.

Unfortunately, we do not have a good answer around this problem
yet. For now, it seems that the only way to safely interact with such
volatile memory is through volatile pointer operations, and never
creating a Rust reference to the memory in question.

** src_rust[:exports code]{VolatileCell} and Concurrency

Another interesting concern is that of concurrency. As peripherals can
be modeled as to behave effectively like another thread, we should
make sure that src_rust[:exports code]{VolatileCell} is safe to use in
these contexts—that is, making sure that it is safe to have a
src_rust[:exports code]{VolatileCell} defined over memory that is
being changed by hardware, and having all accesses be properly
synchronized.

Our analysis of Rust's src_rust[:exports code]{Mutex} gives us
confidence that the mere existence of src_rust[:exports
code]{VolatileCell} over memory that is being modified by hardware
should not be of concern. In particular, this issue was raised [[https://github.com/tock/tock/pull/4129][on a PR
for the Tock operating system]]: given that src_rust[:exports
code]{UnsafeCell} does not make any guarantees about thread safety,
and Rust is always free to dereference its contents based on the
=dereferenceable= attribute, how can it possibly be safe to retain a
reference to it in the first place? However, we can observe that
src_rust[:exports code]{Mutex} does exactly this: it holds a reference
to an src_rust[:exports code]{UnsafeCell} even when it may be modified
concurrently by a different thread. Importantly, src_rust[:exports
code]{Mutex} /does/ ensure that any /direct, intentional/ accesses of
its value are properly synchronized.

This brings us to our second question on synchronization. Here, the
following statement is particularly worrying:
#+begin_quote
In particular, a race between a src_rust[:exports
code]{read_volatile} and any other operation (reading or writing) on
the same location is undefined behavior.
#+end_quote
Does using src_rust[:exports code]{read_volatile} over MMIO memory
that may arbitrary change contents across any two accesses count as a
"data race"?

Unfortunately, atomic operations do not help here either:
#+begin_quote
Since C++ does not support mixing atomic and non-atomic accesses, or
non-synchronized different-sized accesses to the same data, Rust does
not support those operations either.
#+end_quote

I do not see a clear answer to this question. In practice, many
developers rely on volatile accesses are for interacting with such
hardware-modified registers without issues. One of the reasons for
this might be that on most hardware platforms, MMIO read operations
are always consistent: registers are updated atomically by
peripherals, and a CPU will never be exposed to a partial write. It
would be great if the Rust documentation could provide more guidance
for these questions.

** src_rust[:exports code]{VolatileCell} and Happens-Before Relations

Finally, one important aspect to consider is that of volatile
operations and their interactions with regular memory accesses.
Again, Rust provides the following guarantees for volatile memory
operations [emphasis added]:
#+begin_quote
Volatile operations are intended to act on I/O memory, and **are
guaranteed to not be** elided or **reordered by the compiler across
other volatile operations**.
#+end_quote

This is a substantially different guarantee than the
ordering-constraints imposed by atomic operations: while atomics can
establish a /happens-before relation/ between two parts of parallel
threads in a program that affects a /global/ set of variables,
ordering guarantees around volatile operations are constrained to only
these operations. This makes sense for many use-cases of volatile
operations. For instance, it may matter that an "interrupt clear" flag
is written /before/ data is removed from a receive queue, but
generally a peripheral should not be affected by other, independent
memory accesses outside of its MMIO address space.

However, certain peripherals break this assumption, most prominently
ones that perform "Direct Memory Access" (DMA). A DMA-capable
peripheral not only has control over its MMIO registers, but can also
access (a subset of) the same RAM that is accessible to the CPU. These
devices can read from or write to a specified memory region after
being instructed to do so through a write to a MMIO register.

This interaction between volatile accesses to an MMIO register and
access to regular memory can create issues in the face of compiler
optimizations, or hardware-reordering of memory accesses, though. For
example, given that the compiler does not make promises of the order
of volatile operations relative to other memory accesses, it could
happen that a peripheral could read from a buffer prepared by the CPU,
when those buffer writes have not actually been committed to memory
yet.

For this reason, we need to establish an additional, explicit ordering
guarantee between other memory operations and these volatile
accesses. Rust provides us the [[https://doc.rust-lang.org/stable/std/sync/atomic/fn.fence.html][src_rust[:exports
code]{std::sync::atomic::fence}]] function to do just that. This
function works similar to atomic operations and takes an
src_rust[:exports code]{Ordering} argument. It will ensure that
compiler optimizations respect the requested ordering guarantees and,
if applicable, will also emit a CPU instruction that prevents
hardware-based reordering of accesses beyond this point.

Thus, when kicking off an operation that /reads/ from memory written
by the CPU, we must use a src_rust[:exports code]{fence} operation
with an src_rust[:exports code]{Ordering::Release} argument, to ensure
that all writes become visible to another thread (or the hardware)
that is synchronizing with our current thread. For reading data that
the hardware has written into memory, we must use a src_rust[:exports
code]{fence} operation with src_rust[:exports code]{Ordering::Acquire}
instead. This ensures that we are seeing all changes since the point
at which the hardware has informed us that an operation has finished
(e.g., through a volatile read or interrupt).

It should be noted that this relies on a fairly liberal interpretation
of the following comment in src_rust[:exports
code]{std::sync::atomic::fence}'s documentation:
#+begin_quote
A fence ‘A’ which has (at least) Release ordering semantics,
synchronizes with a fence ‘B’ with (at least) Acquire semantics, if
and only if there exist operations X and Y, both operating on some
atomic object ‘M’ such that A is sequenced before X, Y is sequenced
before B and Y observes the change to M. This provides a
happens-before dependence between A and B.
#+end_quote
Here, we assume that the volatile reads and writes to MMIO registers
count as operations that are operating on an /atomic object/. However,
this seems to be a fair assumption to make on many hardware platforms
in practice, and clarifying it likely also ties in to the
considerations of the previous subsection.

# - Interactions of UnsafeCell's =dereferenceable= attribute on volatile
#   (changing) memory, e.g. for DMA or MMIO. Safe? How does this
#   interact with Rust's abstract machine model?
#   - Is this meaningfully different than threads?
#   - How do you "avoid race conditions" as per =UnsafeCell='s
#     documentation on this memory?

* Footnotes :noexport:

[fn:1] In practice, Rust knows which exact function we pass into the
src_rust[:exports code]{writer} argument and generates a src_asm[:exports
code]{fn_cell_test.specialized.1:} symbol that it calls instead. Because our
src_rust[:exports code]{fn cell_test} is marked src_rust[:exports code]{pub}
though, Rust also generates the general src_asm[:exports code]{fn_cell_test:}
symbol that does not make any assumptions on the function passed into its second
argument.
